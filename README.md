# ğŸ¯ Sum-It-Up Agent: Agentic AI Meeting Intelligence Platform

> ğŸš€ **Next-generation AI Agent architecture powered by Model Context Protocol (MCP) for intelligent meeting processing and analysis**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Poetry](https://img.shields.io/badge/Poetry-2.2.1+-60A5FA.svg)](https://python-poetry.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.9+-red.svg)](https://pytorch.org)
[![FastMCP](https://img.shields.io/badge/FastMCP-3.0+-green.svg)](https://fastmcp.com)
[![License](https://img.shields.io/badge/License-Dual%20License-yellow.svg)](LICENSE)

## ğŸŒŸ What Makes This Revolutionary?

**Sum-It-Up Agent** isn't just another transcription toolâ€”it's a **true Agentic AI system** that thinks, reasons, and makes autonomous decisions about how to process your meetings. Built on the cutting-edge **Model Context Protocol (MCP)**, it represents the future of modular, extensible AI architectures.

### ğŸ§  Agentic AI Capabilities

- **ğŸ¯ Autonomous Decision-Making**: The agent analyzes audio characteristics and chooses optimal processing strategies
- **ğŸ” Intelligent Reasoning**: Adapts its approach based on content complexity, user requirements, and constraints
- **ğŸ“‹ Dynamic Planning**: Creates and executes plans that can adapt in real-time to changing conditions
- **âš¡ Smart Optimization**: Balances speed, quality, and cost based on your priorities
- **ğŸ›ï¸ User-Aware Processing**: Intelligently incorporates custom instructions and preferences

## ğŸ—ï¸ MCP-Based Architecture

```
ğŸ¤– Agentic AI Agent
â”œâ”€â”€ ğŸµ Audio Processor MCP Server
â”œâ”€â”€ ğŸ§  Topic Classification MCP Server  
â”œâ”€â”€ ğŸ“ Summarizer MCP Server
â””â”€â”€ ğŸ“§ Communicator MCP Server
```

### ğŸ¯ Why MCP Changes Everything

- **ğŸ“¦ True Modularity**: Each component is an independent server that can be developed, tested, and deployed separately
- **ğŸ”Œ Unlimited Extensibility**: Add new capabilities by creating new MCP servers without touching existing code
- **ğŸŒ Universal Interoperability**: Standardized protocol works across languages, platforms, and cloud providers
- **âš¡ Independent Scaling**: Scale individual components based on their specific resource needs
- **ğŸ§ª Isolated Testing**: Test each component in complete isolation with mocking and stubbing

## ğŸš€ Core Capabilities

### ğŸµ **Audio Processing**
- **Multi-Format Support**: MP3, MP4, WAV, M4A, FLAC, and more
- **Speaker Diarization**: Automatic speaker identification and separation
- **High-Quality Transcription**: State-of-the-art Whisper models with GPU acceleration
- **Format Conversion**: Intelligent audio format optimization
- **Batch Processing**: Handle multiple files efficiently with parallel processing

### ğŸ§  **Topic Classification**
- **Zero-Shot Learning**: Classify meetings without training data
- **Ensemble Methods**: Multiple models working together for higher accuracy
- **Meeting Type Detection**: Automatically identify planning sessions, retrospectives, interviews, and more
- **Confidence Scoring**: Reliable classification with uncertainty quantification

### ğŸ“ **Intelligent Summarization**
- **Template-Based**: Structured summaries tailored to meeting types
- **Multiple LLM Providers**: OpenAI GPT-4, Anthropic Claude, local Ollama models
- **Custom Instructions**: User-aware summarization that adapts to your specific needs
- **Cost Optimization**: Smart token usage and cost estimation
- **Multi-Format Output**: JSON, CSV, TXT, and custom formats

### ğŸ¯ **Agentic Features**
- **ğŸ¤” Reasoning Engine**: Analyzes requirements and chooses optimal approaches
- **ğŸ“Š Quality Assessment**: Evaluates results and decides if reprocessing is needed
- **âš–ï¸ Constraint Handling**: Respects deadlines, budgets, and quality requirements
- **ğŸ”„ Adaptive Learning**: Learns from processing patterns to improve future decisions

## ğŸ› ï¸ Technology Stack

### ğŸ¯ **Core Technologies**
- **ğŸ Python 3.11+**: Modern Python with type hints and async support
- **ğŸ“¦ Poetry 2.2.1**: Dependency management and packaging
- **ğŸ”¥ PyTorch 2.0+**: GPU-accelerated deep learning
- **ğŸ¤— Transformers**: State-of-the-art transformer models
- **ğŸ¤ PyAnnote.audio**: Advanced speaker diarization
- **âš¡ Faster-Whisper**: Optimized speech transcription

### ğŸŒ **AI/ML Infrastructure**
- **ğŸ§  HuggingFace Hub**: Model repository and management
- **ğŸ¦™ Unsloth**: Optimized LLM inference
- **ğŸ”¢ BitsAndBytes**: Efficient quantization
- **ğŸ“Š Scikit-learn**: Machine learning utilities
- **ğŸ¯ FastMCP**: Model Context Protocol implementation

### ğŸ¤– **LLM Integration**
- **ğŸš€ OpenAI**: GPT-3.5, GPT-4, GPT-4-turbo
- **ğŸ§  Anthropic**: Claude-3 family
- **â˜ï¸ Azure OpenAI**: Enterprise-grade OpenAI
- **ğŸ  Local Models**: Ollama, HuggingFace models
- **ğŸ’° Cost Optimization**: Smart token management

## ğŸš€ Quick Start

### ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/sum-it-up-agent.git
cd sum-it-up-agent

# Install dependencies
poetry install

# Set up environment variables (copy .env.example to .env and configure)
cp .env.example .env
# Edit .env with your API keys and MCP server settings
```

### ğŸ¯ Basic Usage

```python
from sum_it_up_agent.audio_processor import AudioProcessingUseCase, ProcessorType
from sum_it_up_agent.topic_classification import TopicClassificationUseCase, ClassifierType
from sum_it_up_agent.summarizer import SummarizationUseCase, SummarizerType

# Process audio file
audio_use_case = AudioProcessingUseCase.create_with_preset(ProcessorType.HIGH_QUALITY)
with audio_use_case.processor:
  segments = audio_use_case.process_audio_file("meeting.mp3", output_format="json")

# Classify meeting type
topic_use_case = TopicClassificationUseCase.create_with_preset(ClassifierType.STANDARD)
with topic_use_case.classifier:
  result = topic_use_case.classify_single_file("meeting_transcription.json")

# Generate intelligent summary
summary_use_case = SummarizationUseCase.create_with_preset(SummarizerType.OPENAI_STANDARD)
with summary_use_case.summarizer:
  summary = summary_use_case.summarize_transcription_file(
    "meeting_transcription.json",
    meeting_type=result.predicted_topic
  )
```

### ğŸ¤– MCP Server Usage

```bash
# Start MCP servers (in separate terminals)
python src/audio_processor/mcp_server_audio.py
python src/topic_classification/mcp_topic_classification.py  
python src/summarizer/mcp_summarizer.py
python src/communicator/mcp_communicator.py

# Use with Agentic AI Agent
from fastmcp import Client

async with Client("http://localhost:9000/mcp_audio_processor") as client:
    result = await client.call_tool("process_audio_file", {
        "audio_path": "meeting.mp3",
        "preset": "high_quality",
        "output_format": "json"
    })
```

## ğŸ¯ Use Cases

### ğŸ¢ **Enterprise Meetings**
- **ğŸ“‹ Planning Sessions**: Action items, decisions, timelines
- **ğŸ”„ Retrospectives**: Lessons learned, improvement opportunities  
- **ğŸ¯ Decision Making**: Options analysis, final decisions, rationale
- **ğŸ’¼ Customer Calls**: Requirements, feedback, next steps

### ğŸ“ **Education & Training**
- **ğŸ“š Lectures**: Key concepts, summaries, study materials
- **ğŸ“ Training Sessions**: Learning objectives, skill assessments
- **ğŸ‘¥ Interviews**: Candidate evaluation, key insights

### ğŸ”¬ **Research & Development**
- **ğŸ§ª Brainstorming**: Idea generation, concept development
- **ğŸ“Š Technical Discussions**: Architecture decisions, trade-offs
- **ğŸ”¬ Lab Meetings**: Experimental results, next steps

## ğŸŒŸ Key Differentiators

### ğŸ¤– **True Agentic AI**
Unlike simple pipeline orchestrators, Sum-It-Up Agent:
- **Thinks** about the best approach for each meeting
- **Reasons** about trade-offs between speed, quality, and cost
- **Adapts** its strategy based on content and requirements
- **Learns** from patterns to improve future processing

### ğŸ—ï¸ **MCP Architecture**
- **ğŸ“¦ Modular**: Each component is an independent, replaceable service
- **ğŸ”Œ Extensible**: Add new capabilities without modifying existing code
- **ğŸŒ Interoperable**: Works with any MCP-compliant service
- **âš¡ Scalable**: Scale components independently based on needs

### ğŸ¯ **Production-Ready**
- **ğŸ›¡ï¸ Error Handling**: Comprehensive error recovery and reporting
- **ğŸ“Š Monitoring**: Detailed logging and performance metrics
- **ğŸ”§ Configuration**: Flexible preset and custom configurations
- **ğŸ§ª Testing**: Extensive test coverage and validation

## ğŸ“Š Performance & Benchmarks

### âš¡ **Processing Speed**
- **ğŸµ Audio Processing**: ~2-5 minutes per hour of audio (GPU)
- **ğŸ§  Classification**: ~10-30 seconds per meeting
- **ğŸ“ Summarization**: ~30-60 seconds per meeting (varies by LLM)

### ğŸ¯ **Accuracy**
- **ğŸ¤ Transcription**: >95% accuracy with high-quality audio
- **ğŸ§  Classification**: >90% accuracy on meeting types
- **ğŸ“ Summarization**: High-quality, structured outputs

### ğŸ’° **Cost Efficiency**
- **ğŸ¤– Smart Optimization**: Automatic cost-quality trade-offs
- **ğŸ’¡ Local Options**: Run everything locally with Ollama
- **ğŸ“Š Estimation**: Accurate cost prediction before processing

## ğŸ› ï¸ Development

### ğŸ—ï¸ **Architecture Overview**

```
src/
â”œâ”€â”€ sum_it_up_agent/         # Main package
â”‚   â”œâ”€â”€ audio_processor/     # Audio processing with diarization
â”‚   â”œâ”€â”€ topic_classification/ # Zero-shot topic classification  
â”‚   â”œâ”€â”€ summarizer/          # LLM-powered summarization
â”‚   â”œâ”€â”€ templates/          # Structured prompt templates
â”‚   â””â”€â”€ communicator/       # Email/MCP communication
â””â”€â”€ examples/               # Usage examples and tutorials
```

### ğŸ”§ **MCP Servers**
- **ğŸµ Audio Processor**: `src/audio_processor/mcp_server_audio.py`
- **ğŸ§  Topic Classification**: `src/topic_classification/mcp_topic_classification.py`
- **ğŸ“ Summarizer**: `src/summarizer/mcp_summarizer.py`
- **ğŸ“§ Communicator**: `src/communicator/mcp_communicator.py`

### ğŸ§ª **Examples & Tutorials**
- **ğŸ“š Basic Usage**: `examples/audio_processing_examples.py`
- **ğŸ¤– MCP Integration**: `examples/mcp_audio_testing.ipynb`
- **ğŸ“ Summarization**: `examples/summarizer_examples.py`
- **ğŸ§  Classification**: `examples/topic_classification_examples.py`

## ğŸŒˆ Roadmap

### ğŸš€ **Coming Soon**
- **ğŸ¯ Multi-Language Support**: Transcription and summarization in 50+ languages
- **ğŸ“Š Real-Time Processing**: Live meeting transcription and analysis
- **ğŸ¤– Advanced Agent Capabilities**: Multi-step reasoning and tool usage
- **ğŸŒ Cloud MCP Services**: Managed MCP servers for enterprise deployment

### ğŸ”® **Future Vision**
- **ğŸ§  AGI Integration**: Advanced reasoning and planning capabilities
- **ğŸ“± Mobile Apps**: Native iOS and Android applications
- **ğŸ”Œ Plugin Ecosystem**: Third-party MCP server marketplace
- **ğŸ¢ Enterprise Features**: SSO, audit logs, compliance

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## CI/CD

This repo uses **GitHub Actions** for a lightweight but robust CI/CD pipeline.

### CI (Pull Requests + main)

Workflow: `.github/workflows/ci.yml`

- **Validates packaging** with `poetry check`
- **Builds artifacts** with `poetry build`
- **Runs a syntax sanity check** via `python -m compileall -q src`

Note: the CI is intentionally kept lightweight and does **not** install the full ML dependency stack.

### CD (Release + Publish)

Workflow: `.github/workflows/release.yml`

Trigger a release by pushing a version tag:

```bash
git tag v0.1.0
git push origin v0.1.0
```

This workflow:

- Builds `sdist` + `wheel`
- Creates a **GitHub Release** and uploads the artifacts
- Publishes to **PyPI** using **trusted publishing** (OIDC)

#### PyPI configuration (one-time)

To enable trusted publishing, configure your PyPI project to trust this GitHub repo/workflow (no API token required). In GitHub, the publish job runs in an environment named `pypi`.

### ğŸ¯ **Important: Dual-Licensing Model**
This project uses a dual-license model to keep development sustainable while remaining free for non-commercial use. All contributors must accept our [Contributor License Agreement (CLA)](CLA.md) to maintain this model.

### ğŸ“‹ **Pull Request Process**
- Use our [PR template](.github/pull_request_template.md) for all submissions
- Ensure all CLA requirements are met
- Follow our code review guidelines

### ğŸ¯ **Areas for Contribution**
- **ğŸ”§ New MCP Servers**: Add new capabilities via MCP
- **ğŸŒ Language Support**: Add transcription for new languages
- **ğŸ“ Templates**: Create new meeting type templates
- **ğŸ§ª Testing**: Improve test coverage and add integration tests
- **ğŸ“š Documentation**: Improve docs and create tutorials

## ğŸ“„ License

This project is offered under a **dual-license model**:

### ğŸ†“ **Non-Commercial License (FREE)**
- âœ… Free for personal, educational, and research use
- âœ… Open source with full access to all features
- ğŸ“‹ See [LICENSE-NONCOMMERCIAL](LICENSE-NONCOMMERCIAL) for complete terms

### ğŸ’¼ **Commercial License (PAID)**
- Required for any commercial use, including:
  - ğŸ¢ For-profit business operations
  - ğŸ’° SaaS/hosted services
  - ğŸ› ï¸ Commercial products or services
  - ğŸ’¼ Paid consulting or training
- ğŸ“§ Contact: **billiosifidis@gmail.com** | **v-iosifidis.com**
- ğŸ“‹ See [LICENSE-COMMERCIAL](LICENSE-COMMERCIAL) for details

### ğŸ“‹ **Contributor License Agreement**
All contributions require acceptance of our [CLA](CLA.md) to maintain dual-licensing model.

ğŸ” **Unsure about your use case?** Contact us for clarification!

## ğŸ™ Acknowledgments

- **ğŸ¤— HuggingFace** for amazing transformer models and tools
- **ğŸ¤ OpenAI** for powerful language models
- **ğŸ§  Anthropic** for Claude models
- **ğŸ¦™ Ollama** for local LLM inference and privacy-focused AI
- **âš¡ FastMCP** for the Model Context Protocol implementation
- **ğŸ¯ PyAnnote** for speaker diarization technology

## ğŸ“ Contact

- **ğŸ“§ Email**: billiosifidis@gmail.com
- **ğŸ› Issues**: [GitHub Issues](https://github.com/yourusername/sum-it-up-agent/issues)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/yourusername/sum-it-up-agent/discussions)

---

## ğŸš€ **Ready to Transform Your Meeting Intelligence?**

**Sum-It-Up Agent** represents the future of **Agentic AI** - systems that don't just process data, but **think, reason, and make intelligent decisions**. With our revolutionary **MCP-based architecture**, you're not just getting a toolâ€”you're getting a platform that can evolve and adapt with your needs.

**â­ Star this repo** to follow our journey toward truly intelligent meeting processing!

**ğŸš€ Try it now** and experience the difference that true Agentic AI can make in your meeting workflow!
