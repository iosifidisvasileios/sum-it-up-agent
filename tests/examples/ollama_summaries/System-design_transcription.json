{
  "metadata": {
    "export_time": "2026-02-12T19:33:16.281291",
    "total_segments": 39,
    "summary": {
      "total_segments": 39,
      "total_duration": 1343.98,
      "speakers": [
        "UNKNOWN",
        "SPEAKER_01",
        "SPEAKER_00"
      ],
      "word_count": 3681,
      "speaker_stats": {
        "UNKNOWN": {
          "segment_count": 2,
          "duration": 1.6599999999999966,
          "word_count": 6,
          "avg_segment_length": 0.8299999999999983
        },
        "SPEAKER_01": {
          "segment_count": 18,
          "duration": 170.34000000000015,
          "word_count": 504,
          "avg_segment_length": 9.463333333333342
        },
        "SPEAKER_00": {
          "segment_count": 19,
          "duration": 1154.83,
          "word_count": 3171,
          "avg_segment_length": 60.78052631578947
        }
      },
      "avg_words_per_segment": 94.38461538461539
    }
  },
  "segments": [
    {
      "start_time": 1.55,
      "end_time": 12.89,
      "duration": 11.34,
      "speaker": "SPEAKER_01",
      "text": "Hello, everyone. Welcome to this system design mock interview. I'm very pleased to say that with me as my candidate today is a former engineering manager at Google. And he's with me now. Mark, how are you?"
    },
    {
      "start_time": 14.59,
      "end_time": 18.73,
      "duration": 4.140000000000001,
      "speaker": "SPEAKER_00",
      "text": "I'm doing great, Tom. Thank you. I'm looking forward to doing this mock interview."
    },
    {
      "start_time": 19.63,
      "end_time": 27.07,
      "duration": 7.440000000000001,
      "speaker": "SPEAKER_01",
      "text": "Yeah, really pleased to have you with us today. Would you mind just introducing yourselves for the viewers so they can know a little bit more about your background?"
    },
    {
      "start_time": 27.07,
      "end_time": 53.01,
      "duration": 25.939999999999998,
      "speaker": "SPEAKER_00",
      "text": "Sure. Yeah. So as you mentioned, I was an engineering manager at Google for about 13 years. And so I did a lot of system designs as part of my job and also did interviews as well as some coaching. And I'm now on the I Got an Offer coaching platform helping candidates with system design and other interviews. And so here's my chance to kind of hopefully show a little bit how it's done."
    },
    {
      "start_time": 54.15,
      "end_time": 72.01,
      "duration": 17.860000000000007,
      "speaker": "SPEAKER_01",
      "text": "Perfect. Yeah. Yeah, Mark's helped. Loads of candidates on our platform get offers at Google and lots of other companies. So do check them out if you're preparing for an interview. Right. Let's crack on with the question. Mark, today I would like you to design Telegram."
    },
    {
      "start_time": 76.33,
      "end_time": 154.41,
      "duration": 78.08,
      "speaker": "SPEAKER_00",
      "text": "OK. Sounds good. All right. So Telegram is, in essence, a messaging application that allows users to send messages to each other and even to groups of people. And it's very big scale. So a lot of users on this on this application. And so I guess for purposes of for purposes of this interview, let me kind of ask you some questions about this. Make sure that I really understand what you want me to design, because Telegram is pretty big. It's pretty complex. It's sophisticated. So let's let's kind of see if I can narrow this down and ask you some questions. So first off, in terms of use cases. Again, I mentioned it's basically about sending and receiving messages. And so I think the primary use case that I'd want to think about is I want to send a message and I want to check messages and read my messages. There's also sort of groups. And so maybe a question to you is, you know, are those the are those the basic use cases that you'd like me to cover in terms of the functionality of the system? And what about groups?"
    },
    {
      "start_time": 155.21,
      "end_time": 171.65,
      "duration": 16.439999999999998,
      "speaker": "SPEAKER_01",
      "text": "Yeah. So, yeah, I think I think that's right. Let's let's go for sending messages and and receiving and reading messages. And I think groups I think we can leave groups to one side just for the purposes of the interview today, just with the time that we've got. Let's let's forget about groups."
    },
    {
      "start_time": 172.49,
      "end_time": 200.63,
      "duration": 28.139999999999986,
      "speaker": "SPEAKER_00",
      "text": "OK, OK. So for now, just kind of one to one messages makes sense. And so then in terms of these messages for just kind of make an assumption. We're really for now, we're just talking about text messages, you know, they can help telegram itself allows you to send larger things, too. But for purposes of this, is it OK if we just kind of talk about sort of messages, text messages, sending, sending, receiving those?"
    },
    {
      "start_time": 202.01,
      "end_time": 202.67,
      "duration": 0.6599999999999966,
      "speaker": "UNKNOWN",
      "text": "Yeah, that's fine."
    },
    {
      "start_time": 202.67,
      "end_time": 203.75,
      "duration": 1.0800000000000125,
      "speaker": "SPEAKER_01",
      "text": "Yeah, let's stick to that."
    },
    {
      "start_time": 204.89,
      "end_time": 250.73,
      "duration": 45.84,
      "speaker": "SPEAKER_00",
      "text": "OK, sounds good. And so let me ask you then a little bit about the OK, so hang on. So in terms of the functional role. Yeah. So in terms of the functional role, what I would like to do as I'm going through this, if that's OK, is I'm not really much of a front end person. I'm sort of worked more on the back end side of things. And so I wouldn't be able to speak a lot about sort of how this shows up in an application. And so the entry point into the system might be APIs, essentially. And I can think of four APIs, which we can go into a little bit later that might reflect that. So I wanted to check with you, is it OK if we sort of use APIs as the entry point into the system design?"
    },
    {
      "start_time": 251.75,
      "end_time": 254.07,
      "duration": 2.319999999999993,
      "speaker": "SPEAKER_01",
      "text": "Yeah, that sounds fine. Fine for me."
    },
    {
      "start_time": 255.37,
      "end_time": 285.35,
      "duration": 29.980000000000018,
      "speaker": "SPEAKER_00",
      "text": "OK. So then let's talk about I think those are the functional requirements. Let's talk a little bit about non-functional requirements. So I think the the one thing that I think about a lot when it comes to non-functional requirements is scale. You know, how big is this? Do we want the system to be? And so maybe tell me a little bit about how many what kind of scale, what kind of how many messages do we want to be able to handle in the system?"
    },
    {
      "start_time": 285.35,
      "end_time": 300.45,
      "duration": 15.099999999999966,
      "speaker": "SPEAKER_01",
      "text": "Yeah, good question. So let's assume that we want to be able to handle 10 billion messages sent every day and we want to be able to double that in, say, a year's time."
    },
    {
      "start_time": 300.45,
      "end_time": 303.75,
      "duration": 3.3000000000000114,
      "speaker": "SPEAKER_00",
      "text": "OK. All right. So that's."
    },
    {
      "start_time": 303.75,
      "end_time": 304.75,
      "duration": 1.0,
      "speaker": "UNKNOWN",
      "text": "OK. All right."
    },
    {
      "start_time": 304.75,
      "end_time": 336.47,
      "duration": 31.720000000000027,
      "speaker": "SPEAKER_00",
      "text": "So that's. That gives me good hints about the some some core ways to think about the system. That's that's useful. Thank you. And then. In terms of all right, so so if we say 10, let's let's use that number just briefly, let me do some quick math here, think through this a little bit. So if I think about 10 billion requests or messages per day and you're talking about sent messages, messages being sent out per day."
    },
    {
      "start_time": 336.47,
      "end_time": 337.47,
      "duration": 1.0,
      "speaker": "SPEAKER_01",
      "text": "Yeah."
    },
    {
      "start_time": 338.29,
      "end_time": 379.65,
      "duration": 41.35999999999996,
      "speaker": "SPEAKER_00",
      "text": "OK, so 10 billion messages. Sent out per day. So if I think about that in terms of transactions per second, because ultimately, you know, servers need to handle things sort of in the moment, there's roughly 100000 seconds in a day. It's not exactly right, but it's close enough for our estimation. So at 100000 seconds in a day, 10 billion requests per day, that translates to about 100000 messages per second. And if you then take into account, you know, maybe peaks. Yeah. Yeah. Yeah. Yeah. Like during the day, let's just say half a million requests per second or so. Does that seem reasonable? Does that seem OK?"
    },
    {
      "start_time": 379.65,
      "end_time": 385.89,
      "duration": 6.240000000000009,
      "speaker": "SPEAKER_01",
      "text": "Yeah, that seems accurate. Yeah, I think that's it. I think that's the right the right ballpark."
    },
    {
      "start_time": 385.89,
      "end_time": 471.83,
      "duration": 85.94,
      "speaker": "SPEAKER_00",
      "text": "OK, and so then, as you said, doubling in a year. So that would be mean, you know, we need to be able to handle a million of these. And so really what this translates to is we need to be able to horizontally scale the system. So, again, that's good hints. And so if I then think about just roughly a servers that might need to be able to handle this on the front end anyway, we can get into that detail. But like a server might be able to handle a typical server, 10000 requests per second. So just ballparking this, maybe 50 servers to start with. And if we do this in a way that allows scaling automatically, a last elastic allows some scaling, not less. But sort of. And the elastic growth or whatever you want to call it, that's not the right term. Anyway, scaling automatic auto scaling, that's the word I'm looking for at Amazon and other places allow that so that that the number of servers can scale with traffic. You know, then next year at a million requests, you know, you might need 100 servers, something like that. And you could add more for some overhead and things like that. But that's roughly the idea that I'm thinking about in terms of size. And then if and then let me ask you a little bit about the size of the messages. So so we talked about text. So would it be fair to say, hey, you know, your typical message is about 100 bytes?"
    },
    {
      "start_time": 471.83,
      "end_time": 475.47,
      "duration": 3.640000000000043,
      "speaker": "SPEAKER_01",
      "text": "Yeah, that sounds like trip."
    },
    {
      "start_time": 475.47,
      "end_time": 523.69,
      "duration": 48.22000000000003,
      "speaker": "SPEAKER_00",
      "text": "So at 10 billion messages sent per day and 100 bytes, so 10 billion is like 10 giga, so that would be 10 times 100 is 1000 giga, which is a terabyte. So roughly a terabyte of data per day. And if you multiply that per year, then now we're talking three hundred sixty five terabytes. If you want to say a couple of years, three years, obviously that's roughly a petabyte of data. And so this also gives me a hint in terms of what kind of back end to maybe think about for this system design. So. All right. So that's that's helpful. That gives me some some ideas. And then the other thing I want to ask you about non-functional requirements. Is what about, you know, availability, for example, of the system?"
    },
    {
      "start_time": 523.69,
      "end_time": 531.73,
      "duration": 8.039999999999964,
      "speaker": "SPEAKER_01",
      "text": "Yeah, sure. We want the system to be highly available. We don't want users to ever experience downtime."
    },
    {
      "start_time": 531.73,
      "end_time": 542.11,
      "duration": 10.379999999999995,
      "speaker": "SPEAKER_00",
      "text": "OK. OK, makes sense, I mean, it's a it's a live system. And then what about latency?"
    },
    {
      "start_time": 542.11,
      "end_time": 554.17,
      "duration": 12.059999999999945,
      "speaker": "SPEAKER_01",
      "text": "Yeah, typically we want things to happen in the app almost instant instantaneously, right from from a user perspective. So we're talking about hundreds of milliseconds for the API."
    },
    {
      "start_time": 554.17,
      "end_time": 628.91,
      "duration": 74.74000000000001,
      "speaker": "SPEAKER_00",
      "text": "OK. OK, and so I'm going to make an assumption that we actually want hundreds of milliseconds or even just a hundred, whatever that number is in that range that we want that for like the 90th or 95th percentile of requests, meaning we don't want that for the 50th percentile, the average number of requests, because then we might have other 50th percentile requests. We might have other 50 percent of requests that take way longer and we don't want that. So we want the majority of the requests, the large majority of requests to complete within a few hundred milliseconds. And so in terms of measuring these things, we want to make sure that we're monitoring, you know, the average is good to monitor. But the 90th, 95th percentile, those are of tail end latencies are more important to monitor. And we'd want to have in place monitoring to be able to look at that so that we can make sure that we are actually hitting our targets there. So, you know. 10, 10 billion sent messages a day, we want, you know, very low latency and we want that to be available. So really, we want that that the system to to feel very responsive and feel always available to users. That's kind of where I'm where I'm seeing this going."
    },
    {
      "start_time": 628.91,
      "end_time": 633.15,
      "duration": 4.240000000000009,
      "speaker": "SPEAKER_01",
      "text": "OK, yeah, absolutely. OK."
    },
    {
      "start_time": 633.15,
      "end_time": 678.33,
      "duration": 45.180000000000064,
      "speaker": "SPEAKER_00",
      "text": "And then if I think about. I'm going to make an assumption here that because these messages, if I send you a message, it's not critical that the I mean, we talked about latency in terms of response time to me as I'm sending it. And if you're on the receiving end and you're getting your messages, you want that to be responsive. But I don't I'm going to make an assumption that it's not super important that when I send the message and I get a response back that you immediately write and see the message. It's OK if that if it shows up, you know, in just. A second or two or three or something like that. So what I'm getting out there is I think eventual consistency here is is OK in terms of the data delivery."
    },
    {
      "start_time": 678.33,
      "end_time": 682.17,
      "duration": 3.839999999999918,
      "speaker": "SPEAKER_01",
      "text": "Is that fair? Yeah. Yeah, that's fair."
    },
    {
      "start_time": 682.17,
      "end_time": 698.43,
      "duration": 16.25999999999999,
      "speaker": "SPEAKER_00",
      "text": "OK. OK, good. All right. I think those are let me think. I think those are the those are kind of the probably the most important things I can think of at the moment in terms of functional, non-functional requirements."
    },
    {
      "start_time": 698.67,
      "end_time": 748.57,
      "duration": 49.90000000000009,
      "speaker": "SPEAKER_01",
      "text": "With big system design questions like this, you want to quickly work out what's in and out of scope. Mark was able to do this fairly quickly, confirming the key functional and non-functional elements with the interviewer. You also want to reduce the scope. After all, you don't have time to design everything. Mark did this by excluding one aspect of the design groups. It's generally a good idea to get to a working solution first before scaling out and getting complex. If you try to cover all functionalities right from the off, you might never have time to actually get to a working solution. Before you start sketching out your high level design, you'll also need to work out some key metrics and capacity planning to inform your decision making. However, you don't want to spend lots of time doing detailed calculations. Mark got the balance here just right. He did some quick maths to go from daily traffic to traffic per second, as well as coming up with a ballpark figure for the amounts of bytes needed."
    },
    {
      "start_time": 748.57,
      "end_time": 1193.52,
      "duration": 444.94999999999993,
      "speaker": "SPEAKER_00",
      "text": "So let's now let's let's maybe do some quick API design. I think I've got a Google drawing here up that I'm going to use. And bear with me as I'm you know, I'm not this is not going to be pretty, but I'll try and do the best I can here. So what I'm actually going to call this here, telegram mock. All right. Let me put a let me just put some talk a little bit about APIs. And then what I want to do is I want to get into the high level design, if that's OK. Yeah, sounds good. All right. I'm going to try and if this text size doesn't work or whatever, just let me know. But I'm going to just talk about APIs right here. So I think it's. I think of in terms of the use cases we talked about, send a message, receive a message. I really think of four different APIs, maybe or three or four APIs that I can think about. And I'm going to use very poor rest representation here, and I'm not going to do it for all of them. But so to start with a rest API for sending a message might be, you know, whatever the domain of this thing is going to be, you know, telegram dot CEO or something like that. And then messages. Maybe V1 for versioning. And let's see here. And then what I would do is the the HTTP request post request is probably the most appropriate thing with a body that contains sort of the information of this message. And so what would I want in this message? I guess I would want maybe my sender ID, which is identifying me as who's sending this thing. I probably would want. I guess I would want maybe my sender ID, which is identifying me as who's sending this thing. I probably would want. Oh, sorry. It would be like something like, I don't know. It's either going to be some name mangled thing that's sort of some identifier or it's going to be some generated ID. I'm not sure. And then recipient ID, which is, you know, who am I sending it to? You know, and this could be, you know, Jones, some number. And then maybe I would want. The text, I guess, really, for purposes of what we're talking about. Pardon the auto capitalization here. That's just and then would be hi there. How's it going? Something like that. And this would be roughly the body. And then I would get back as kind of standard HTTP response codes. 200 if everything is OK. 400 something if there's some sort of error with my with, you know, there's some limitations. Maybe there's some other errors or something like that in the server side. So anyway, that would be the roughly an API call to send a message, send a message to somebody. And just to be clear, the header of this message would have authentication to make sure I can't fake, you know, the sender, et cetera, things like that. There would be some standard things in here. So this would be one. So let me let me actually label this thing. This would be send a message. OK. All right. And then. So I said for API, so let me just run down the four APIs and we can kind of get so there's check messages and check messages would be basically seeing, do I have any new messages? And this similarly to the other one, you know, messages, the one and this might be a get request with there's no there's no body. It's just to get request and what it might return as a response is a list of is a list of messages. Anyway, message IDs or something like that. So that would turn to OK. OK, so that would be to see do I have any new messages if I'm on the receiving end of things? And then there might be an actual like a read a message and read a message might be similar to that. I'm not going to go into details here. But but you get the idea that, you know, I would send a probably get request with a message ID actually. So it might be something like. Yeah. Amen. A. Thank you. Thank you, Banks. Thank you. Thank you. Thank you, okay. Thank you so much. said I wasn't gonna go into detail here I am anyway a message with the I'm gonna just do this one briefly messages v1 and then I'm gonna say message ID oops equals whatever the message ID is so dot dot dot and then then there's a question so here's a question about like yeah so you I could mark messages read mark messages read for example could be another API anyway I should I should stop is that good enough for API is is that kind of give you an idea of what okay great yeah I'm gonna put that down the corner if that's okay I'm actually gonna make that smaller now and just get it out of the way a little bit so let me just think about this for a moment and see if I think about the so I've calculated some we've I think we've covered functional non-functional requirements we've calculated some some metrics that we need to pay attention to and of course we want to look at total messages per day as you know as we're looking at growth and things like that in terms of high level components that might be a good thing to just sort of talk about a little bit or kind of identify so if I were to just draw some some basic things here I might say here's an application and slash user on a phone this is a bit smaller and this application might talk to we probably want given the scale and given the requirements here we will want a load balancer that winds up directing the traffic to a set of application servers that can scale so that that we distribute the load evenly, and there's different strategies to load balancing. You can wind up doing what's called round robin, where it just goes and it just distributes one after the other one just around robin as it's called. There could be one with least CPU or least loaded, I guess is the right term, where it looks at the load of the servers and it sends it to the ones that are least loaded. You can actually do the reverse too. There's reasons to do that, but we're not going to get into that. There's different load balancing strategies, but I think we need a load balancer here because we need to be able to scale. Then behind the load balancer, we would have basically app servers or API. Let me call them API server. Again, I'm going to make this a little bit smaller so that this is a little bit. Then just to be super clear here, there's many of these. I think we talked about when I was talking about the traffic numbers earlier, I think I said, maybe we want 50 of these roughly to handle peak or something like that. Imagine there's 50 of these guys and the load balancer distributes that. Does that make sense?"
    },
    {
      "start_time": 1193.52,
      "end_time": 1199.42,
      "duration": 5.900000000000091,
      "speaker": "SPEAKER_01",
      "text": "Yeah. I don't think we did put a number in it, but I think that's right. 50 sounds about right to me."
    },
    {
      "start_time": 1199.42,
      "end_time": 1257.46,
      "duration": 58.039999999999964,
      "speaker": "SPEAKER_00",
      "text": "Yeah. Let me just recap that. If we have a half a million requests per second coming in for sends, this is only for sending. Each server, each API server, let's say it can handle 10,000 send requests per second, then we would want 50 just doing the math. To be fair, getting messages might be more frequent actually than sending, especially in a group environment. We said we weren't going to talk about that. You might double that. Maybe we've got 100 or something like that. That's the API servers. These are the things that basically take these APIs that we just talked about a moment ago. And process the request and translate that to what needs to happen in the backend on the backend server side. Is this visible? Are you able to see this okay on your screen?"
    },
    {
      "start_time": 1257.46,
      "end_time": 1259.4,
      "duration": 1.9400000000000546,
      "speaker": "SPEAKER_01",
      "text": "Yeah, looks good."
    },
    {
      "start_time": 1259.4,
      "end_time": 1269.94,
      "duration": 10.539999999999964,
      "speaker": "SPEAKER_00",
      "text": "All right. Let me just stop for just a moment just to give you a chance if you have any questions or anything I'm missing so far."
    },
    {
      "start_time": 1269.94,
      "end_time": 1271.9,
      "duration": 1.9600000000000364,
      "speaker": "SPEAKER_01",
      "text": "No, it looks good to me."
    },
    {
      "start_time": 1271.9,
      "end_time": 1343.98,
      "duration": 72.07999999999993,
      "speaker": "SPEAKER_00",
      "text": "Okay. Let me continue with some of the components here that I'm thinking about. If I jump, skip a couple of steps here. Let me see if I can actually find one of these. Oh, look at that. There's actually a shape for, oh my gosh, a database. A database. Let's talk about the types of databases here. There's different types of databases that you could use for applications. There are mostly really two categories of databases. There are SQL databases, relational databases, maybe I should say, where you can do very complex queries. You can have complex data relationships, and so that's a pro, that's a positive. So it allows you very easily to query very complex multifaceted types of data. The drawback of a database that is a SQL or a relational database, of course, is that it's harder to scale those. When I talked earlier about"
    }
  ]
}